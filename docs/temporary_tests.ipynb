{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "from typing import List\n",
    "from stemmabench.config_parser import ProbabilisticConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25\n"
     ]
    }
   ],
   "source": [
    "def repeat_character(n:int=10, char:str=\"word\", sep:str=\" \"):\n",
    "    \"\"\"\n",
    "    Generate a fake text.\n",
    "    \"\"\"\n",
    "    return sep.join([f\"{char}{i}\"  for i in range(1, n + 1)])\n",
    "\n",
    "DEMO_TEXT = repeat_character(25)\n",
    "print(DEMO_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 Error\n",
      "0 - 25 sentences - word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25\n",
      "0.25 - 20 sentences - word1 word2 word3 word4 word5 word6 word7 word8 word10 word11 word14 word16 word17 word19 word20 word21 word22 word23 word24 word25\n",
      "0.5 - 17 sentences - word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word18 word21 word22 word23 word24 word25\n",
      "0.75 - 24 sentences - word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25\n",
      "1 - 8 sentences - word1 word2 word3 word4 word5 word23 word24 word25\n",
      "2 Error\n"
     ]
    }
   ],
   "source": [
    "def fragment(text: str, \n",
    "             max_frag_rate: float, \n",
    "             frag_loc_dist: ProbabilisticConfig={\n",
    "                 \"law\": \"Binomial\",\n",
    "                 \"rate\": 0.5\n",
    "             }, \n",
    "             sep: str=\" \",\n",
    "             random_state=None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Fragment a given text by randomly removing words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be fragmented.\n",
    "        max_frag_rate (float): The maximum allowable word removal rate.\n",
    "        frag_loc_dist (dict): Dictionary specifying the distribution of fragment locations.\n",
    "            \"law\" (str): Distribution type (\"Binomial\", \"Uniform\", \"Poisson\").\n",
    "            \"rate\" (float): Distribution parameter determining the probability.\n",
    "        sep (str, optional): The separator used to split the input text into words. Default is a space.\n",
    "        random_state (int or None, optional): Seed for random number generation. Default is None.\n",
    "\n",
    "    Returns:\n",
    "        str: A fragmented text with words removed.\n",
    "    \"\"\"\n",
    "    # Check if the fragmentation rate is valid.\n",
    "    if not 0 <= max_frag_rate <= 1:\n",
    "        raise ValueError(\"Maximum fragmentation rate must be between 0 and 1.\")\n",
    "    \n",
    "    # Initialize a random number generator.\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    \n",
    "    # Split the text into a list of words and get total word count.\n",
    "    words = text.split(sep)\n",
    "    n_words = len(words)\n",
    "    indices = range(n_words)\n",
    "\n",
    "    # Generate a distribution for word indices based on the specified law.\n",
    "    if frag_loc_dist[\"law\"] == \"Binomial\":\n",
    "        locations_dist = scipy.stats.binom.pmf(k=indices, n=n_words, \n",
    "                                      p=frag_loc_dist[\"rate\"])\n",
    "    elif frag_loc_dist[\"law\"] == \"Uniform\":\n",
    "        locations_dist = np.full(shape=n_words, fill_value=1/n_words)\n",
    "    elif frag_loc_dist[\"law\"] == \"Poisson\":\n",
    "        locations_dist = scipy.stats.poisson.pmf(k=indices, \n",
    "                                                 mu=frag_loc_dist[\"rate\"])\n",
    "    else:\n",
    "        raise ValueError(\"Only 'Binomial', 'Uniform', and 'Poisson' laws are \\\n",
    "                         supported.\")\n",
    "    locations_dist = locations_dist / locations_dist.sum()\n",
    "    # Calculate the number of fragment locations based on the fragment rate.\n",
    "    frag_rate = rng.uniform(low=0, high=max_frag_rate)\n",
    "    n_frag_loc = int(frag_rate * n_words) \n",
    "\n",
    "    # Choose 'n_frag_loc' fragment locations according to 'locations_dist'.\n",
    "    frag_locations = rng.choice(indices, size=n_frag_loc, replace=False, \n",
    "                                p=locations_dist)\n",
    "    \n",
    "    # Remove words at the selected fragment locations.\n",
    "    words = np.delete(words, frag_locations)\n",
    "    \n",
    "    # Join the remaining words to form the fragmented text.\n",
    "    fragmented_text = sep.join(words)\n",
    "    \n",
    "    return fragmented_text\n",
    "\n",
    "\n",
    "# Tests : different rate, different distribution Binomial, Uniform, Poisson and an other external\n",
    "rates = [-1, 0, 0.25, 0.5, 0.75, 1, 2]\n",
    "for rate in rates:\n",
    "    try:\n",
    "        res = fragment(DEMO_TEXT, max_frag_rate=rate)\n",
    "        length = len(res.split(\" \")) # approx\n",
    "        print(f\"{rate} - {length} sentences - {res}\")\n",
    "    except:\n",
    "        print(rate, \"Error\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemmabench.textual_units.word import Word\n",
    "from stemmabench.textual_units.text import Text\n",
    "textstr = f\"I am {None} going to run. Now!\"\n",
    "text = Text(textstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from stemmabench.stemma_generator import Stemma\n",
    "from stemmabench.config_parser import StemmaBenchConfig\n",
    "from loguru import logger\n",
    "# Set logging level to info\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = StemmaBenchConfig(**{\n",
    "    \"meta\": {\n",
    "      \"language\": \"eng\"  \n",
    "    },\n",
    "\n",
    "    \"stemma\": {\n",
    "        \"depth\": 3,\n",
    "        \"width\": {\n",
    "            \"law\": \"Uniform\",\n",
    "            \"min\": 2,\n",
    "            \"max\": 4\n",
    "        },\n",
    "        \"fragmentation_proba\": 1\n",
    "    },\n",
    "\n",
    "    \"variants\": {\n",
    "        \"sentences\": {\n",
    "            \"duplicate\": {\n",
    "                \"args\": {\n",
    "                    \"nbr_words\": 1\n",
    "                },\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.5\n",
    "            }\n",
    "        },\n",
    "        \"words\": {\n",
    "            \"synonym\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.05,\n",
    "                \"args\": {}\n",
    "            },\n",
    "            \"mispell\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.001,\n",
    "                \"args\": {}\n",
    "            },\n",
    "            \"omit\": {\n",
    "                \"law\": \"Bernouilli\",\n",
    "                \"rate\": 0.001,\n",
    "                \"args\": {}\n",
    "            }\n",
    "        },\n",
    "        \"text\": {\n",
    "            \"fragmentation\": {\n",
    "                \"max_rate\": 1,\n",
    "                \"distribution\": {\n",
    "                    \"law\": \"Bernouilli\",\n",
    "                    \"rate\": 0.5\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tree({\n",
       "  \"word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25\": {\n",
       "    \"Word1 word2 word3 word4 word5 word6  word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": {\n",
       "      \"Word1 word2 word3 word4 word5 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": {\n",
       "        \"Word1 word2 word3 word4 word5 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": [\n",
       "          \"Word1 word1 word2 word3 word4 word5 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\"\n",
       "        ],\n",
       "        \"Word1 word2 word3 word4 word5 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": [\n",
       "          \"Word1 word2 word3 word4 word5 word6 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word8 word9 word10 word11 word12 word13 word14 word15 word16 word16 word17 word17 word17 word18 word19 word20 word21 word22 word23 word24 word25.\"\n",
       "        ]\n",
       "      }\n",
       "    },\n",
       "    \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": {\n",
       "      \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\": {\n",
       "        \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word24 word25.\": [\n",
       "          \"Word1 word2 word3 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word22 word23 word24 word24 word25.\"\n",
       "        ],\n",
       "        \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\": [\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word23 word24 word25.\"\n",
       "        ],\n",
       "        \"Word1 word2  word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\": [\n",
       "          \"Word1 word2 word4 word5 word6 word7 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word4 word5 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word4 word5 word6 word6 word7 word8 word9 word10 word11 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\"\n",
       "        ]\n",
       "      },\n",
       "      \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": {\n",
       "        \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": [\n",
       "          \"Word1 word2 word3 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word23 word24 word25.\"\n",
       "        ],\n",
       "        \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25.\": [\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word9 word10 word11 word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word20 word21 word22 word23 word24 word25.\",\n",
       "          \"Word1 word2 word3 word4 word5 word6 word7 word8 word9 word9 word10  word12 word12 word13 word14 word15 word16 word17 word18 word19 word20 word21 word22 word23 word23 word24 word25.\"\n",
       "        ]\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a Stemma object.\n",
    "stemma = Stemma(original_text=DEMO_TEXT, config=config)\n",
    "\n",
    "# Generate a tradition.\n",
    "stemma.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access generate texts.\n",
    "stemma.texts_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access edges.\n",
    "stemma.edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StemmaBench",
   "language": "python",
   "name": "stemmabench_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
